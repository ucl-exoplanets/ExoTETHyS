= ExoTETHyS.BOATS User Manual
:author: Giuseppe Morello
:sectnums:
:sectnumlevels: 2
:toc: preamble
:toclevels: 4
:source-language: python
:experimental:
:xrefstyle: short

[big]#*Bias in the Occultation Analysis of Transiting Systems*#

image::https://github.com/ucl-exoplanets/ExoTETHyS/blob/master/logo.png[width=10%]
*version: 2.x.x - beta*

ifdef::env-github[]
:tip-caption: :bulb:
:note-caption: :information_source:
:important-caption: :heavy_exclamation_mark:
:caution-caption: :fire:
:warning-caption: :warning:
endif::[]

[preamble]
== Introduction
The BOATS subpackage is designed to evaluate the impact of common approximations in modeling transit and eclipse light curves, such as neglecting the planet's flux or its variation with phase. Additionally, it can also be used:

- to calculate the absolute photometric fluxes and spectra of individual objects, exoplanetary systems and binaries;
- as a versatile S/N ratio calculator for observations with a long list of predefined instruments as well as user-supplied ones;
- to compute the transit duration, equilibrium temperature and other exoplanet atmospheric parameters.

The main functions rely on a minimal set of parameters that describe the orbital geometry and orientation, sizes and temperatures of the two bodies to compute the biases in transit/eclipse depth. Good estimates can de obtained by assuming blackbody emission spectra from star, exoplanet dayside and nightside. Pre-calculated grids of stellar spectra are also available. Users can provide their own spectra for each of the 3 components.

I refer to the https://arxiv.org/pdf/[photometry article] and https://arxiv.org/pdf/[spectroscopy article] for an introduction to the scientific motivations, mathematics and a detailed description of the core algorithms.

== User instructions

To compute the transit/eclipse depth biases you just need to import this subpackage and run the boats_calculate_transit/boats_calculate_eclipse function with a configuration file:
[source, bash]
```
>>> from exotethys import boats  
>>> boats.boats_calculate_transit('PATH_TO_ROOT/examples/boats_example1.txt')   
>>> boats.boats_calculate_eclipse('PATH_TO_ROOT/examples/boats_example5.txt')  
```
NOTE: The same configuration file could be used for either transit or eclipse calculation. +
If running both cases with the same configuration file, the output files are overwritten. +
To avoid this issue, you can use two configuration files differing only for the names and/or location of the output files.

In the following subsection I describe the configuration file and explain the various options available. Then I discuss the examples of configuration files that are available in the GitHub repository and show how to read the file products.

TIP: Although the BOATS subpackage has been conceived with a specific purpose in mind, most functions can be used independently and/or in different combinations to perform various tasks.

In the last subsection, I discuss other possible usage of the BOATS functions.

=== BOATS configuration file
The BOATS configuration file is a text file in which each line begins with a keyword followed by one or more values associated with the keyword. The lines starting with # are ignored; keyword values preceded by ! are also ignored. Examples of configuration files can be found in the "examples" folder.

Below I describe the available keywords:

*stellar_models_grid* (MANDATORY) +
values: _Phoenix_2018_, _Phoenix_2012_13_, _Atlas_2000_, _Stagger_2015_, _Blackbody_ or _Userfile_ +
only one choice per run (i.e., configuration file) is allowed

*planet_models_grid* (MANDATORY) +
values: _Blackbody_ or _Userfile_ +
only one choice per run (i.e., configuration file) is allowed

*star_model_path* (only if _Userfile_ stellar_models_grid, optional) +
values: path to user star model file

*star_model_file* (only if _Userfile_ stellar_models_grid, mandatory) +
values: user star model file name

*rescale_star_flux* (only if _Userfile_ stellar_models_grid, mandatory) +
values: _Yes_ or _No_ +
_Yes_ if the user stellar spectrum has to be rescaled by the dilution factor: (star radius / distance from the observer)^2 +
_No_ if the user stellar spectrum already accounts for the dilution factor

*planet_day_model_path* (only if _Userfile_ planet_models_grid, optional) +
values: path to user file for the planet dayside

*planet_day_model_file* (only if _Userfile_ planet_models_grid, mandatory) +
values: user planet dayside file name

*planet_night_model_path* (only if _Userfile_ planet_models_grid, optional) +
values: path to user file for the planet nightside

*planet_night_model_file* (only if _Userfile_ planet_models_grid, mandatory) +
values: user planet nightside file name

*rescale_planet_flux* (only if _Userfile_ planet_models_grid, mandatory) +
values: _Yes_ or _No_ +
_Yes_ if the user planet dayside and nightside spectra have to be rescaled by the dilution factor: (planet radius / distance from the observer)^2 +
_No_ if the user planet dayside and nightside spectra already account for the dilution factor

*passbands_path* (OPTIONAL) +
values: path to user passbands

*passbands* (MANDATORY) +
values: built-in passband names if not passbands_path (same of file names at PATH_TO_ROOT/exotethys/Passbands/, without the .pass extension) or user file names including extension

*wavelength_bins_path* (OPTIONAL) +
values: path to wavelength bins files

*wavelength_bins_files* (OPTIONAL) +
values: user file names or _no_bins_ (if given, one entry per passband) +
The user files must be text files with 2 columns reporting the lower and upper limits of the desired wavelength bins within the corresponding passband (each row defines a wavelength bin).

*telescope_area* (MANDATORY) +
values: float type (positive)

*telescope_area_unit* (MANDATORY) +
values: string representation of astropy.unit area (e.g., 'm2'='m**2', 'cm2')

*observing_duration* (MANDATORY) +
values: float type (transit_duration T_14 < observing_duration < period_orbital - transit_duration T_14)

*observing_duration_unit* (MANDATORY) +
values: string representation of astropy.unit time (e.g., 'hour' = 'hr' = 'h', 'second' = 's') or T_14

*star_effective_temperature* (MANDATORY, except if _Userfile_ stellar_models_grid & not planet_circulation_efficiency) +
values: float type (range depending on the stellar_models_grid)

*star_log_gravity* (OPTIONAL) +
values: float type (range depending on the stellar_models_grid, default is 4.5)

*star_metallicity* (OPTIONAL) +
values: float type (range depending on the stellar_models_grid, default is 0.0)

*star_radius* (MANDATORY) +
values: float type (positive)

*star_radius_unit* (MANDATORY) +
values: string representation of astropy.unit length (e.g., 'solRad'='Rsun', 'km', 'm')

*orbital_semimajor_axis* (MANDATORY) +
values: float type (orbital_semimajor_axis > star_radius)

*orbital_semimajor_axis_unit* (MANDATORY) +
values: string representation of astropy.unit length (e.g., 'au'='AU', 'km', 'm') or star_radius

*orbital_inclination* (MANDATORY) +
values: float type (0 deg < = orbital_inclination < = 90 deg)

*orbital_inclination_unit* (MANDATORY) +
values: string representation of astropy.unit angle (e.g., 'deg', 'rad'='radian')

*orbital_period* (MANDATORY) +
values: float type (positive)

*orbital_period_unit* (MANDATORY) +
values: string representation of astropy.unit time (e.g., 'd'='day') or T_14

*planet_bond_albedo* (OPTIONAL) +
values: float type (0 < = planet_bond_albedo < = 1, default is 0.0)

*planet_circulation_efficiency* (OPTIONAL, not if _Userfile_ planet_models_grid, not if planet_day_temperature and planet_night_temperature) +
values: float type (0 < = planet_circulation_efficiency < = 1, default is 0.0)

*planet_day_temperature* (OPTIONAL, not if _Userfile_ planet_models_grid, not if planet_circulation_efficiency) +
values: float type (positive)

*planet_night_temperature* (OPTIONAL, not if _Userfile_ planet_models_grid, not if planet_circulation_efficiency) +
values: float type (positive)

*planet_radius* (MANDATORY) +
values: float type (positive)

*planet_radius_unit* (MANDATORY) +
values: string representation of astropy.unit length (e.g., 'jupiterRad'='Rjup', 'km', 'm') or star_radius

*system_distance* (MANDATORY) +
values: float type (system_distance >= 1 AU)

*system_distance_unit* (MANDATORY) +
values: string representation of astropy.unit length (e.g., 'pc'='parsec')

*output_path* (OPTIONAL) +
values: path to where to store the results

*output_filename* (OPTIONAL) +
values: string type (without extension)

*output_fileext* (OPTIONAL) +
values: _.pickle_ (default) and/or _.txt_


=== Description of examples

*boats_example1*: This example is to compute the bias over a single instrument passband with wavelength bins, using _Phoenix_2012_13_ stellar_models_grid, _Blackbody_ planet_models_grid with given planet_day_temperature and planet_night_temperature. It creates two files named "WASP43b_NIRISS_SOSS_pho1213_bb_Td1600_Tn850_A0e23.pickle" and "WASP43b_NIRISS_SOSS_pho1213_bb_Td1600_Tn850_A0e23.txt".

*boats_example2*: This example is to compute the bias over two instrument passbands with wavelength bins, using _Blackbody_ stellar_models_grid, _Blackbody_ planet_models_grid with given planet_day_temperature and planet_night_temperature. It creates a file named "WASP43b_NIRISS_NIRSpec_bb_bb_Td1600_Tn850_A0e23.pickle".

*boats_example3*: This example is to compute the bias over a single instrument passband with wavelength bins, using _Blackbody_ stellar_models_grid, _Userfile_ planet_models_grid. It creates a file named "WASP43b_NIRISS_SOSS_bb_ace_Td1600_Tn850_A0e23.pickle".

*boats_example4*: This example is to compute the bias over a single instrument passband with wavelength bins, using _Userfile_ stellar_models_grid, _Userfile_ planet_models_grid. It creates a file named "WASP43b_MIRI_LRS_jy_ace_Td1600_Tn850_A0e23.pickle".

*boats_example5*: This example differs from boats_example4 only for the output_filename. It creates a file named "WASP43b_MIRI_LRS_jy_ace_Td1600_Tn850_A0e23_eclipse.pickle".

NOTE: In principle, all examples can be used for either transit or eclipse calculation, but I am assuming that the transit case is more interesting to study.

*boats_example6*: This example is to compute the bias over four instrument passbands without wavelength bins, using _Blackbody_ stellar_models_grid, _Blackbody_ planet_models_grid with a list of planet_bond_albedo and planet_circulation_efficiency. It creates a file named "WASP43b_JWST_bb_bb_various_Ab_eps.pickle".

*boats_example7*: This example is to compute the bias over two instrument passbands one with one without wavelength bins, using _Blackbody_ stellar_models_grid, _Blackbody_ planet_models_grid with a list of planet_bond_albedo and planet_circulation_efficiency. It creates a file named "WASP43b_NIRISS_MIRInobins_bb_bb_various_Ab_eps.pickle".

*boats_example8*: This example is to compute the bias over four instrument passbands without wavelength bins, using _Blackbody_ stellar_models_grid, _Blackbody_ planet_models_grid with a list of planet_bond_albedo and planet_circulation_efficiency. It creates a file named "WASP43b_JWST_bb_bb_various_Tday_tnight.pickle".


=== BOATS output files
When running boats.boats_calculate_transit or boats.boats_calculate_eclipse, the results can be stored in files with the extension _.txt_ and/or _.pickle_.
POSSIBLY DESCRIBE THE TXT FILES
The _pickle_ format is specifically designed to save objects created with _python_ (https://pythontips.com/2013/08/02/what-is-pickle-in-python/[more info]).
The objects created with SAIL.ldc_calculate are _python_ https://docs.python.org/3/tutorial/datastructures.html#dictionaries[dictionaries].

Here I show how to read such files through some examples.

==== Basic individual
Let's open the file "Sun_ldc.pickle" that has been created by running the sail_example8:
[source, bash]
```
>>> import pickle
>>> sun_ldc_file = pickle.load(open('Sun_ldc.pickle','rb'),encoding='latin1')
```
We already know that it contains a dictionary, therefore we can ask for its keys:
[source, bash]
```
>>> sun_ldc_file.keys()
dict_keys(['star_params', 'passbands'])
```
The "star_params" branch ends with a numpy array containing the stellar parameters of this target:
[source, bash]
```
>>> sun_ldc_file['star_params']
array([5.78e+03, 4.50e+00, 0.00e+00])
```
The "passbands" branch contains other keys for the requested passbands:
[source, bash]
```
>>> sun_ldc_file['passbands'].keys()
dict_keys(['uniform_phoenix_2012_13', 'uniform_phoenix_2012_13_10880.0_16800.0', 'uniform_phoenix_2012_13_11108.0_16432.0', 'uniform_phoenix_2012_13_11108.0_11416.0', 'uniform_phoenix_2012_13_11416.0_11709.0', 'uniform_phoenix_2012_13_11709.0_11988.0', 'uniform_phoenix_2012_13_11988.0_12257.0', 'uniform_phoenix_2012_13_12257.0_12522.0', 'uniform_phoenix_2012_13_12522.0_12791.0', 'uniform_phoenix_2012_13_12791.0_13058.0', 'uniform_phoenix_2012_13_13058.0_13321.0', 'uniform_phoenix_2012_13_13321.0_13586.0', 'uniform_phoenix_2012_13_13586.0_13860.0', 'uniform_phoenix_2012_13_13860.0_14140.0', 'uniform_phoenix_2012_13_14140.0_14425.0', 'uniform_phoenix_2012_13_14425.0_14719.0', 'uniform_phoenix_2012_13_14719.0_15027.0', 'uniform_phoenix_2012_13_15027.0_15345.0', 'uniform_phoenix_2012_13_15345.0_15682.0', 'uniform_phoenix_2012_13_15682.0_16042.0', 'uniform_phoenix_2012_13_16042.0_16432.0'])
```
The passband keys include:

- 'uniform_phoenix_2012_13', i.e., the requested passband;

- 'uniform_phoenix_2012_13_lambda1_lambda2', where lambda1 and lambda2 are the lower and upper limits of the requested wavelength bins (in Angstrom).

Let's now explore what is inside one of these passband keys:
[source, bash]
```
>>> sun_ldc_file['passbands']['uniform_phoenix_2012_13_10880.0_16800.0'].keys()
dict_keys(['claret4', 'gen_claret1', 'gen_claret2', 'gen_claret3', 'gen_claret4', 'gen_claret5', 'gen_claret6'])
```
The new keys correspond to the requested limb-darkening laws. The number after 'gen_claret' denote the order. +
We look inside 'claret4':
[source, bash]
```
>>> sun_ldc_file['passbands']['uniform_phoenix_2012_13_10880.0_16800.0']['claret4'].keys()
dict_keys(['coefficients', 'weighted_rms_res'])
```
These are the last keys, containing the limb-darkening coefficients for this choice of star+passband+law and the quality of the fit:
[source, bash]
```
>>> sun_ldc_file['passbands']['uniform_phoenix_2012_13_10880.0_16800.0']['claret4']['coefficients']
array([ 0.44803605,  0.25590171, -0.18203445,  0.01312166])
>>> sun_ldc_file['passbands']['uniform_phoenix_2012_13_10880.0_16800.0']['claret4']['weighted_rms_res']
array([5.62612442e-05])
```
We have a quick look at the other laws to show that _gen_claret4_ is equivalent to _claret4_ and that the quality of the fit is lower/higher when using less/more coefficients (in this particular case, lower order laws are subsets of the higher order ones):
[source, bash]
```
>>> sun_ldc_file['passbands']['uniform_phoenix_2012_13_10880.0_16800.0']['gen_claret4']['coefficients']
array([ 0.44803605,  0.2559017 , -0.18203444,  0.01312165])
>>> sun_ldc_file['passbands']['uniform_phoenix_2012_13_10880.0_16800.0']['gen_claret4']['weighted_rms_res']
array([5.62612442e-05])
>>> sun_ldc_file['passbands']['uniform_phoenix_2012_13_10880.0_16800.0']['gen_claret2']['coefficients']
array([ 0.68720911, -0.10129642])
>>> sun_ldc_file['passbands']['uniform_phoenix_2012_13_10880.0_16800.0']['gen_claret2']['weighted_rms_res']
array([0.00081957])
>>> sun_ldc_file['passbands']['uniform_phoenix_2012_13_10880.0_16800.0']['gen_claret6']['coefficients']
array([ 0.62487639, -0.17728853,  0.13867818,  0.29065234, -0.52615743,
        0.20857673])
>>> sun_ldc_file['passbands']['uniform_phoenix_2012_13_10880.0_16800.0']['gen_claret6']['weighted_rms_res']
array([1.46248395e-05])
```

==== Complete individual
Let's now explore the other two output files that have been created by running the sail_example8, because of the request of the _complete_ user_output:
[source, bash]
```
>>> sun_neighbour_ldc_file = pickle.load(open('HD209458bSunCool_neighbour_ldc.pickle','rb'),encoding='latin1')
>>> sun_neighbour_ints_file = pickle.load(open('HD209458bSunCool_neighbour_intensities.pickle','rb'),encoding='latin1')
>>> sun_neighbour_ldc_file.keys()
dict_keys(['teff03000_logg5.50_MH0.0', 'teff05700_logg4.5_MH0.0', 'teff05800_logg4.5_MH0.0', 'teff06100_logg4.5_MH0.0'])
>>> sun_neighbour_ints_file.keys()
dict_keys(['teff03000_logg5.50_MH0.0', 'teff05700_logg4.5_MH0.0', 'teff05800_logg4.5_MH0.0', 'teff06100_logg4.5_MH0.0'])
```
The first level of keys is identical for the two files, as it contains the labels associated with the neighbour models that have been used to compute the requested targets in the sail_example8. +
For the neighbour ldc file, the structure of the next level dictionaries is similar to that of the basic output, but with more information. For example, after selecting one specific passbands, you get the following keys:
[source, bash]
```
>>> sun_neighbour_ldc_file['teff06100_logg4.5_MH0.0']['passbands']['uniform_phoenix_2012_13_10880.0_16800.0'].keys()
dict_keys(['rescaled_mu', 'rescaled_intensities', 'weights', 'laws'])
```
The 'laws' contains the information about the limb-darkening coefficients and quality of the fit for the selected neighbour model and passband. For example:
[source, bash]
```
>>> sun_neighbour_ldc_file['teff06100_logg4.5_MH0.0']['passbands']['uniform_phoenix_2012_13_10880.0_16800.0']['laws']['claret4']['coefficients']
array([ 0.40234082,  0.28553471, -0.19583254,  0.01317074])
>>> sun_neighbour_ldc_file['teff06100_logg4.5_MH0.0']['passbands']['uniform_phoenix_2012_13_10880.0_16800.0']['laws']['claret4']['weighted_rms_res']
6.696820777468198e-05
```
The other three keys contain the information about the processed intensity profile and weights adopted in the corresponding fit, each key containing a 1D numpy array of the same size. 

We can visually compare the rescaled model intensities with the corresponding values obtained with the claret4 coefficients:
[source, bash]
```
>>> rescaled_mu = sun_neighbour_ldc_file['teff06100_logg4.5_MH0.0']['passbands']['uniform_phoenix_2012_13_10880.0_16800.0']['rescaled_mu']
>>> rescaled_intensities = sun_neighbour_ldc_file['teff06100_logg4.5_MH0.0']['passbands']['uniform_phoenix_2012_13_10880.0_16800.0']['rescaled_intensities']
>>> claret4_coefficients = sun_neighbour_ldc_file['teff06100_logg4.5_MH0.0']['passbands']['uniform_phoenix_2012_13_10880.0_16800.0']['laws']['claret4']['coefficients']
>>> claret4_intensities = sail.get_intensities_from_ldcs(rescaled_mu, claret4_coefficients, 'claret4')
>>> import matplotlib.pyplot as plt
>>> plt.plot(rescaled_mu, rescaled_intensities, 'b.', label='intensities')
[<matplotlib.lines.Line2D object at 0x18156288d0>]
>>> plt.plot(rescaled_mu, claret4_intensities, 'r', label='claret4')
[<matplotlib.lines.Line2D object at 0x182077bd90>]
```

The neighbour intensities file contains the original mu values and the corresponding passband intensities, that we can compare with the rescaled ones:
[source, bash]
```
>>> original_mu = sun_neighbour_ints_file['teff06100_logg4.5_MH0.0']['mu']
>>> original_intensities = sun_neighbour_ints_file['teff06100_logg4.5_MH0.0']['uniform_phoenix_2012_13_10880.0_16800.0']
>>> plt.plot(original_mu, original_intensities, 'k.',label='original')
[<matplotlib.lines.Line2D object at 0x18207e4690>]
>>> plt.plot(rescaled_mu, rescaled_intensities, 'b.',label='rescaled')
[<matplotlib.lines.Line2D object at 0x1820a29590>]
```
After some restyling, you could obtain the two panels of the figure below:

[[intensity_profiles]]
.Left panel: Rescaled intensity profile (blue dots) and fitted profile with claret-4 limb-darkening coefficients (red line). Right panel: Original intensity profile (black dots) and rescaled intensity profile (blue dots). Note the slightly different mu values between the two profiles. Read the https://arxiv.org/pdf/1908.09599.pdf[reference paper] for information about the underlying procedure.
image::https://github.com/ucl-exoplanets/ExoTETHyS/blob/v2-beta/user_manuals/figures/merge_rescaled_vs_claret4_et_original_intensities.png[width=100%]


NOTE: These profiles can be used as input for generating the transit light-curves with the TRIP subpackage (link:TRIP_manual.adoc[TRIP manual]).

NOTE: If you are interested to the intensity profiles rather than limb-darkening coefficients, you should choose the _grid_ calculation_type and _complete_ user_output. The intensity profiles can be provided only for the models in the database; these are not interpolated to obtain the intensity profiles of stars with different sets of parameter values.

=== Other SAIL functions
The list of functions available within SAIL subpackage can be obtained by typing the standard python command `dir(sail)`. All functions are documented with docstrings.
For example:
[source, bash]
```
>>> print(sail.get_intensities_from_ldcs.__doc__)

    This function computes the model intensities given the limb-darkening coefficients
    
    :param np.array mu: 1D array with mu values
    :param np.array coefficients: 1D array with the limb-darkening coefficients
    :param str law: name of the limb-darkening law
    :return: the intensities at the given mu values
    :rtype: np.array
```
The function "sail.get_intensities_from_ldcs" has been added to enable quick visualization of the intensity profile from the calculated LDCs, but it is not used during the LDCs calculation.

The function "sail.get_grid_parameters" can be used to know the range and sampling of stellar parameter space covered by the grids in the database, and it is also used during the LDCs calculation.

In the future we might add/hightlight here other functions, depending on the users feedback.

== Database files
Some stellar model files will be needed during a SAIL run. The necessary files will be downloaded automatically during the run, unless these files are already found in a directory inside `PATH_HOME/.exotethys`. Such files are a collateral output of ExoTETHyS.SAIL, as they are only needed to perform other calculations. +
However, the database files contain valuable information even outside the ExoTETHyS framework. Therefore, I explain how to read the database files.

The manage_database subpackage (link[manual]) can be used to find out the path and names of the database files:
[source, bash]
```
>>> from exotethys import manage_database as mdb
>>> path, filenames = mdb.ls_database(grid='Phoenix_2012_13')
>>> path
'/Users/pepe/.exotethys/Phoenix_2012_13'
>>> filenames
['teff03000_logg5.50_MH0.0.pickle', 'teff05700_logg4.5_MH0.0.pickle', 'teff05800_logg4.5_MH0.0.pickle', 'teff06100_logg4.5_MH0.0.pickle']
```
Note that the database files have _pickle_ format and contain _python_ dictionaries. Let's now read one of these files:
[source, bash]
```
>>> import os, pickle
>>> chosen_file_path = os.path.join(path, 'teff05800_logg4.5_MH0.0.pickle')
>>> content = pickle.load(open(chosen_file_path,'rb'),encoding='latin1')
>>> content.keys()
dict_keys(['mu', 'wavelengths', 'star_params', 'intensities', 'fluxes'])
```
- The "star_params" branch contains a numpy array with the stellar parameters. +
- The "wavelengths" branch contains a https://docs.astropy.org/en/stable/units/[quantity array] with the model wavelengths. +
- The "mu" branch contains a numpy array of positions on the stellar disk. +
- The "intensities" branch contains a 2D numpy array with the model intensities at the tabulated mu and wavelengths. +
- The "fluxes" branch contains the disk-integrated flux at the stellar surface.


